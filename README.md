# LH_CD_JOSE_OLIVEIRA_NETO  
# DESAFIO INDICIUM LIGHTHOUSE - DESAFIO DE CIÃŠNCIA DE DADOS - IMDB


Este repositÃ³rio contÃ©m a resoluÃ§Ã£o do desafio de CiÃªncia de Dados, envolvendo:
- AnÃ¡lises estatÃ­sticas e EDA (Exploratory Data Analysis).
- CriaÃ§Ã£o e treinamento de modelo preditivo.
- Salvamento do modelo final em formato `.pkl`.

## ğŸ“‚ Estrutura do RepositÃ³rio
Â´Â´Â´
â”œâ”€â”€ desafio_indicium_imdb.csv # Base de dados utilizada
â”œâ”€â”€ eda_modelagem.ipynb # Notebook com anÃ¡lise, EDA e modelagem
â”œâ”€â”€ models/
â”‚ â””â”€â”€ modelo.pkl # Modelo treinado salvo
â”œâ”€â”€ requirements.txt # DependÃªncias do projeto
â””â”€â”€ README.md # DocumentaÃ§Ã£o do repositÃ³rio
Â´Â´Â´

## âš™ï¸ Como executar o projeto

1. **Clonar o repositÃ³rio:**
   ```bash
   git clone https://github.com/JoseNeto1981/LH_CD_JOSE_OLIVEIRA_NETO.git
   cd LH_CD_JOSE_OLIVEIRA_NETO


## Criar um ambiente virtual:
python -m venv venv
venv\Scripts\activate      # Windows


## Instalar dependÃªncias:
pip install -r requirements.txt

## Abrir o notebook:
jupyter notebook - comando utilizado dentro do pycharm

## Principais dependÃªncias:
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- joblib

## ğŸ¯ Motivo do Desafio
O objetivo deste desafio foi aplicar na prÃ¡tica conceitos de **CiÃªncia de Dados**, desde a anÃ¡lise exploratÃ³ria atÃ© a construÃ§Ã£o de um modelo preditivo.  
A ideia central Ã© demonstrar a capacidade de transformar uma base de dados bruta (IMDB) em **insights relevantes** e um **modelo treinado**, seguindo boas prÃ¡ticas de anÃ¡lise e documentaÃ§Ã£o.

---

## ğŸ§© Metodologia Utilizada
A resoluÃ§Ã£o do desafio foi estruturada em etapas:

1. **ExploraÃ§Ã£o dos Dados (EDA)**  
   - AnÃ¡lise inicial da base (`desafio_indicium_imbd.csv`), verificando tipos de variÃ¡veis, valores ausentes e estatÃ­sticas descritivas.  
   - VisualizaÃ§Ã£o grÃ¡fica de distribuiÃ§Ãµes, correlaÃ§Ãµes e padrÃµes relevantes.  

2. **PrÃ©-processamento**  
   - Limpeza e tratamento de valores faltantes.  
   - NormalizaÃ§Ã£o e codificaÃ§Ã£o de variÃ¡veis, quando necessÃ¡rio.  

3. **Modelagem**  
   - Teste de diferentes algoritmos de machine learning (ex.: RegressÃ£o Linear, Ãrvores de DecisÃ£o, Random Forest).  
   - SeleÃ§Ã£o do modelo com melhor desempenho baseado em mÃ©tricas de avaliaÃ§Ã£o adequadas (ex.: RMSE, RÂ², acurÃ¡cia).  

4. **ValidaÃ§Ã£o**  
   - DivisÃ£o treino/teste para medir generalizaÃ§Ã£o do modelo.  
   - Ajuste de hiperparÃ¢metros, quando necessÃ¡rio.  

5. **PersistÃªncia do Modelo**  
   - O modelo final foi salvo em `models/modelo.pkl` usando `joblib`, permitindo reuso em aplicaÃ§Ãµes futuras.  

---

## ğŸ“‘ RelatÃ³rios
- Todas as anÃ¡lises estatÃ­sticas e o EDA estÃ£o documentados no notebook [`untiled2.ipynb`](untiled2.ipynb).
- TambÃ©m disponibilizado em [`desafio_indicium_imdb.pdf`](desafio_indicium_imdb.pdf) para facilitar a visualizaÃ§Ã£o em formato de relatÃ³rio.
- O modelo final foi salvo em [`models/modelo.pkl`](models/modelo.pkl).


## âœ… ConsideraÃ§Ãµes Finais
- O desafio cumpriu seu papel ao mostrar o fluxo completo de um projeto de CiÃªncia de Dados: **da exploraÃ§Ã£o ao produto final (modelo salvo)**.  
- Durante o processo, foi possÃ­vel identificar **fatores determinantes** para as variÃ¡veis-alvo e avaliar a qualidade do modelo.  
- A organizaÃ§Ã£o do repositÃ³rio foi feita para facilitar a reprodutibilidade, contendo:
  - Base de dados utilizada.  
  - Notebook com anÃ¡lises e cÃ³digo.  
  - Modelo treinado salvo.  
  - DocumentaÃ§Ã£o (README).  

Este projeto reforÃ§a a importÃ¢ncia de uma abordagem estruturada e bem documentada em CiÃªncia de Dados, onde cada etapa contribui para a confiabilidade e aplicabilidade do resultado final.


   
